{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dp3XgzEq5L0c"
      },
      "source": [
        "#### **Set an environment**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "d4UIZyGZ5B5v"
      },
      "outputs": [],
      "source": [
        "!pip install datasets\n",
        "!pip install tensorboard\n",
        "!pip install huggingface_hub\n",
        "!pip install -q transformers accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jcNgHxD85S75"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import set_seed\n",
        "\n",
        "DEVICE = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "MODEL_NAME = \"roberta-base\"\n",
        "SEED = 42\n",
        "\n",
        "print(DEVICE)\n",
        "set_seed(SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIiu2l3yKXTX"
      },
      "source": [
        "#### **Load & preprocess a dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b3ucbFKeK2kX"
      },
      "outputs": [],
      "source": [
        "# load a dataset.\n",
        "from datasets import Dataset\n",
        "\n",
        "data = Dataset.from_json(\"HW4.json\") # you must upload a HW4.json before execute this line.\n",
        "data = data.rename_column(\"intent\", \"labels\")\n",
        "\n",
        "# split a dataset into train, validation and dev(test) dataset.\n",
        "raw_train_data = data.filter(lambda item: item[\"split\"] == \"train\")\n",
        "split_data = raw_train_data.train_test_split(test_size=0.1, seed=SEED)\n",
        "train_data = split_data[\"train\"]\n",
        "val_data = split_data[\"test\"]\n",
        "\n",
        "dev_data = data.filter(lambda item: item[\"split\"] == \"dev\")\n",
        "\n",
        "print(f\"Train dataset size: {len(train_data)}\")\n",
        "print(f\"Validation dataset size: {len(val_data)}\")\n",
        "print(f\"Dev dataset size: {len(dev_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C7TyIchKNBkB"
      },
      "outputs": [],
      "source": [
        "import ast\n",
        "\n",
        "# label2id & id2label\n",
        "unique_labels = set()\n",
        "for item in data:\n",
        "  item[\"labels\"] = ast.literal_eval(item[\"labels\"])\n",
        "  for intent in item[\"labels\"]:\n",
        "    unique_labels.add(intent)\n",
        "\n",
        "unique_labels = sorted(list(unique_labels))\n",
        "num_labels = len(unique_labels)\n",
        "\n",
        "label2id = {label: idx for idx, label in enumerate(unique_labels)}\n",
        "id2label = {idx: label for idx, label in enumerate(unique_labels)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZGjGXnRl2WbV"
      },
      "outputs": [],
      "source": [
        "def encode_labels(item):\n",
        "  label_vector = [0]*num_labels\n",
        "  item[\"labels\"] = ast.literal_eval(item[\"labels\"])\n",
        "\n",
        "  for label in item[\"labels\"]:\n",
        "    label_vector[label2id[label]] = 1\n",
        "\n",
        "  item[\"labels\"] = [float(x) for x in label_vector]\n",
        "  return item\n",
        "\n",
        "train_data = train_data.map(encode_labels)\n",
        "val_data = val_data.map(encode_labels)\n",
        "dev_data = dev_data.map(encode_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LpbhC23W22Wi"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "def tokenize_function(item):\n",
        "  return tokenizer(item[\"utterance\"], padding=\"max_length\", truncation=True)\n",
        "\n",
        "train_data = train_data.map(tokenize_function, batched=True)\n",
        "val_data = val_data.map(tokenize_function, batched=True)\n",
        "dev_data = dev_data.map(tokenize_function, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6YAPnWFgzb7T"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "  logits, labels = eval_pred\n",
        "\n",
        "  top2_predictions = np.zeros_like(logits, dtype=np.int32)\n",
        "  for i, logit in enumerate(logits):\n",
        "    top2_indices = np.argsort(logit)[-2:]\n",
        "    top2_predictions[i, top2_indices] = 1\n",
        "\n",
        "  precision, recall, f1, _ = precision_recall_fscore_support(labels, top2_predictions, average=\"micro\")\n",
        "  accuracy = accuracy_score(labels, top2_predictions)\n",
        "\n",
        "  return {\n",
        "      \"accuracy\": accuracy,\n",
        "      \"precision\": precision,\n",
        "      \"recall\": recall,\n",
        "      \"f1\": f1\n",
        "  }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yeABhbUlVzAe"
      },
      "outputs": [],
      "source": [
        "def quantitative_eval(metrics):\n",
        "  print(f\"Accuracy: {metrics['test_accuracy']:.2f}\")\n",
        "  print(f\"Precision: {metrics['test_precision']:.2f}\")\n",
        "  print(f\"Recall: {metrics['test_recall']:.2f}\")\n",
        "  print(f\"F1: {metrics['test_f1']:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1. Fine-tune RoBERTa models**"
      ],
      "metadata": {
        "id": "tWotXhyMlGdz"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmWDdE4RSS5f"
      },
      "source": [
        "#### **Define hyperparameters**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "argument = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    num_train_epochs=10,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    learning_rate=1e-3,\n",
        "    max_grad_norm=1.0,\n",
        "    weight_decay=0.0,\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    warmup_ratio=0.1,\n",
        "    dataloader_num_workers=2,\n",
        "    dataloader_drop_last=True,\n",
        "    fp16=True,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    report_to=\"tensorboard\",\n",
        "    seed=SEED,\n",
        ")"
      ],
      "metadata": {
        "id": "6MSgGT5xlkxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    r=8,                              # Rank\n",
        "    lora_alpha=32,                    # Scaling factor\n",
        "    target_modules=[\"query\", \"key\"],  # Attention\n",
        "    lora_dropout=0.1,                 # Dropout rate\n",
        "    task_type=\"SEQ_CLS\",              # Task type\n",
        ")"
      ],
      "metadata": {
        "id": "ACUMXj-Emi3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXjloFUcJ3JJ"
      },
      "source": [
        "#### **Define functions for training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "snXjIX3x7mAx"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "from peft import get_peft_model\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    problem_type=\"multi_label_classification\",\n",
        "    num_labels=num_labels,\n",
        "    id2label=id2label,\n",
        "    label2id=label2id\n",
        ").to(DEVICE)\n",
        "\n",
        "model = get_peft_model(model, lora_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8tsECIgscK_l"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "# define a trainer for training\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=argument,\n",
        "    train_dataset=train_data,\n",
        "    eval_dataset=val_data,\n",
        "    processing_class=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ds0jScQbJYRU"
      },
      "source": [
        "#### **Train & test RoBERTa models**\n",
        "1. Test a vanilla RoBERTa model.\n",
        "2. Fine-tune a model.\n",
        "3. Test a fine-tuned RoBERTa model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDfC_fMUKBL5"
      },
      "source": [
        "##### **Teat a vanilla RoBERTa model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LmkBd8efIbRS"
      },
      "outputs": [],
      "source": [
        "# evaluate a vanilla RoBERTa model\n",
        "logits, true_labels, metrics = trainer.predict(dev_data)\n",
        "quantitative_eval(metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNo5Bos-XsEV"
      },
      "source": [
        "##### **Open a tensorboard to monitor the training process**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6WNqoSdXe8a"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir ./results/runs/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qFHDOt0KGHb"
      },
      "source": [
        "##### **Fine-tune & test a model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_D39_QLV9AC6"
      },
      "outputs": [],
      "source": [
        "# fine-tune a model\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NDY6m1fZJUFD"
      },
      "outputs": [],
      "source": [
        "# evaluate a fine-tuned RoBERTa model\n",
        "metrics = trainer.predict(dev_data).metrics\n",
        "quantitative_eval(metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2. Use the fine-tuned model uploaded to Huggingface hub**"
      ],
      "metadata": {
        "id": "gUVjh_1biJ8p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer,AutoModelForSequenceClassification\n",
        "from peft import PeftModel\n",
        "\n",
        "# import the fine-tuned model from huggingface.\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"twkang43/lora-roberta-cse4057\")\n",
        "base_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    problem_type=\"multi_label_classification\",\n",
        "    num_labels=num_labels,\n",
        "    id2label=id2label,\n",
        "    label2id=label2id\n",
        ").to(DEVICE)\n",
        "model = PeftModel.from_pretrained(base_model, \"twkang43/lora-roberta-cse4057\")"
      ],
      "metadata": {
        "id": "Us8vEKUip_aF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "# define a trainer for evaluation\n",
        "evaluation = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    do_eval=True,\n",
        "    per_device_eval_batch_size=16,\n",
        "    dataloader_num_workers=2,\n",
        "    dataloader_drop_last=True,\n",
        "    fp16=True,\n",
        "    report_to=\"tensorboard\",\n",
        "    seed=SEED,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=evaluation,\n",
        "    processing_class=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "id": "4awGD7arqZVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = trainer.predict(dev_data).metrics\n",
        "quantitative_eval(metrics)"
      ],
      "metadata": {
        "id": "jH89gCQmsNLe"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}